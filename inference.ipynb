{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation import GenerationConfig\n",
    "from skimage.filters import threshold_otsu, gaussian, median, unsharp_mask\n",
    "from skimage.measure import label, regionprops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import custom library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prompt\n",
    "import dataset\n",
    "import preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import torch and check cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(1234)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model VLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = \"/root/letractien/Mammo-VLM/.cache\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-VL-Chat\", trust_remote_code=True, cache_dir=CACHE_DIR)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-VL-Chat\", device_map=device, trust_remote_code=True, cache_dir=CACHE_DIR).eval()\n",
    "model.generation_config = GenerationConfig.from_pretrained(\"Qwen/Qwen-VL-Chat\", trust_remote_code=True, cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_annotation_tuples = dataset.load_image_annotation_tuples()\n",
    "save_dir = \"out/detect_qwen_with_preprocess\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "log_path = os.path.join(save_dir, \"log.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (img_path, annotation) in enumerate(image_annotation_tuples):\n",
    "\n",
    "    # folder = annotation['study_id']\n",
    "    # os.makedirs(os.path.join(save_dir, folder), exist_ok=True)\n",
    "\n",
    "    basename = annotation['image_id']\n",
    "    # img_png_path = os.path.join(save_dir, folder, f\"{basename}.png\")\n",
    "\n",
    "    ds = pydicom.dcmread(img_path)\n",
    "    # plt.imsave(img_png_path, ds.pixel_array, cmap=\"gray\")\n",
    "\n",
    "    img_arr = ds.pixel_array.astype(np.float32)\n",
    "    # img_with_bbox = preprocess.draw_bbox_grayscale(img_arr, annotation, color=255, thickness=5)\n",
    "\n",
    "    x, m, new_annotation = preprocess.crop(img_arr, annotation=annotation)\n",
    "    norm = preprocess.truncation_normalization(x, m)\n",
    "\n",
    "    step1 = preprocess.median_denoise(norm, disk_radius=3)\n",
    "    step2 = preprocess.unsharp_enhance(step1, radius=1.0, amount=1.5)\n",
    "    step3 = preprocess.morphological_tophat(step2, selem_radius=15)\n",
    "    step4 = preprocess.non_local_means_denoise(step3, patch_size=5, patch_distance=6, h_factor=0.8)\n",
    "    step5 = preprocess.wavelet_enhancement(step4, wavelet='db8', level=1)\n",
    "    final = preprocess.clahe(step5, clip_limit=0.02)\n",
    "    disp = preprocess.normalize_for_display(final)\n",
    "    disp = np.nan_to_num(disp)\n",
    "    disp = preprocess.draw_bbox_grayscale(disp.copy(), new_annotation, color=255, thickness=5)\n",
    "\n",
    "    # img_png_path_pre = os.path.join(save_dir, folder, f\"{basename}_preprocessed.png\")\n",
    "    img_png_path_pre = os.path.join(save_dir, f\"{basename}_preprocessed.png\")\n",
    "    Image.fromarray(disp).save(img_png_path_pre)\n",
    "\n",
    "    history = [(\n",
    "        f'Picture 1: <img>{img_png_path_pre}</img>\\n这是什么?', \n",
    "        prompt.generate_mammogram_description(\n",
    "            laterality=annotation['laterality'],\n",
    "            view_position=annotation['view_position'],\n",
    "            breast_density=annotation['breast_density'],\n",
    "            breast_birads=annotation['breast_birads'],\n",
    "            finding_categories=annotation['finding_categories'],\n",
    "            finding_birads=annotation['finding_birads'],\n",
    "            width=new_annotation['width'],\n",
    "            height=new_annotation['height'],\n",
    "            xmin=new_annotation['xmin'],\n",
    "            ymin=new_annotation['ymin'],\n",
    "            xmax=new_annotation['xmax'],\n",
    "            ymax=new_annotation['ymax'],\n",
    "        )\n",
    "    )]\n",
    "\n",
    "    query = tokenizer.from_list_format([\n",
    "        {'image': img_png_path_pre},\n",
    "        {'text': prompt.generate_request_description}\n",
    "    ])\n",
    "\n",
    "    response, history = model.chat(tokenizer, query=query, history=history)\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Response {idx}: {response}\\n\")\n",
    "        f.write(f\"History {idx}: {history}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    image = tokenizer.draw_bbox_on_latest_picture(response, history)\n",
    "    if image:\n",
    "        # image.save(os.path.join(save_dir, folder, f\"{basename}_{idx}_bbox.png\"))\n",
    "        image.save(os.path.join(save_dir, f\"{basename}_{idx}_bbox.png\"))\n",
    "    else:\n",
    "        print(\"No bbox\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matplotlib show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Thư mục lưu kết quả đã chạy trước đó\n",
    "save_dir = \"out/detect_qwen_with_preprocess\"\n",
    "\n",
    "# Lấy danh sách file \"_preprocessed.png\"\n",
    "pre_files = sorted([f for f in os.listdir(save_dir) if f.endswith(\"_preprocessed.png\")])\n",
    "\n",
    "for f_pre in pre_files:\n",
    "    basename = f_pre.replace(\"_preprocessed.png\", \"\")\n",
    "    \n",
    "    # Ảnh gốc DICOM đã xử lý thành PNG (nếu bạn muốn đọc từ DICOM gốc thì phải load lại từ dataset)\n",
    "    original_path = os.path.join(save_dir, f\"{basename}_preprocessed.png\")  # ảnh đã qua preprocess nhưng chưa bbox\n",
    "    bbox_files = [f for f in os.listdir(save_dir) if f.startswith(basename) and f.endswith(\"_bbox.png\")]\n",
    "\n",
    "    # Nếu có ảnh bbox thì lấy, nếu không bỏ qua\n",
    "    if not bbox_files:\n",
    "        print(f\"[!] Không tìm thấy bbox cho {basename}\")\n",
    "        continue\n",
    "    bbox_path = os.path.join(save_dir, bbox_files[0])\n",
    "\n",
    "    # Đọc ảnh\n",
    "    img_original = Image.open(original_path)\n",
    "    img_bbox = Image.open(bbox_path)\n",
    "\n",
    "    # Hiển thị song song\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].imshow(img_original, cmap=\"gray\")\n",
    "    axes[0].set_title(\"Preprocessed Image\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(img_bbox, cmap=\"gray\")\n",
    "    axes[1].set_title(\"Image with BBox\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    plt.suptitle(f\"Sample: {basename}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-mammography",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
